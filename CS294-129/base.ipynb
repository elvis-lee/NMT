{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "MAX_LENGTH = 25\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path\n",
    "data_dir = os.path.join('datasets', 'nmt_data_vi')\n",
    "train_source = 'train.vi'\n",
    "train_target = 'train.en'\n",
    "train_source_dir = os.path.join(data_dir, train_source)\n",
    "train_target_dir = os.path.join(data_dir, train_target)\n",
    "vocab_source = 'vocab.vi'\n",
    "vocab_target = 'vocab.en'\n",
    "vocab_source_dir = os.path.join(data_dir, vocab_source)\n",
    "vocab_target_dir = os.path.join(data_dir, vocab_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences in source training set: 133317\n",
      "Total number of sentences in target training set: 133317\n"
     ]
    }
   ],
   "source": [
    "# load training sets\n",
    "with open(train_source_dir) as f_source:\n",
    "    sentences_source = f_source.readlines()\n",
    "with open(train_target_dir) as f_target:\n",
    "    sentences_target = f_target.readlines()\n",
    "\n",
    "# check the total number of sentencs in training sets    \n",
    "print(\"Total number of sentences in source training set: {}\".format(len(sentences_source)))\n",
    "print(\"Total number of sentences in target training set: {}\".format(len(sentences_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the longest sentence in sentences_source: 25\n",
      "The longest sentence: \n",
      "['Trong', '4', 'phút', ',', 'chuyên', 'gia', 'hoá', 'học', 'khí', 'quyển', 'Rachel', 'Pike', 'giới', 'thiệu', 'sơ', 'lược', 'về', 'những', 'nỗ', 'lực', 'khoa', 'học', 'miệt', 'mài', 'đằng']\n"
     ]
    }
   ],
   "source": [
    "# Truncate sentences by maximum length\n",
    "sentences_source = list(map(lambda src:src.split()[:MAX_LENGTH], sentences_source))\n",
    "sentences_target = list(map(lambda src:src.split()[:MAX_LENGTH], sentences_target))\n",
    "\n",
    "# check the longest sentence after sentence truncation\n",
    "max = 0\n",
    "for s in sentences_source:\n",
    "    if len(s) > max:\n",
    "        max = len(s)\n",
    "        max_s = s\n",
    "print(\"Number of words in the longest sentence in sentences_source: {}\".format(max))\n",
    "print(\"The longest sentence: \\n{}\".format(max_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nummber of words in source vocabulary: 7709\n",
      "Total nummber of words in target vocabulary: 17191\n"
     ]
    }
   ],
   "source": [
    "# load vocabularies\n",
    "\n",
    "# index2word\n",
    "with open(vocab_source_dir) as f_vocab_source:\n",
    "    #index2word_source = f_vocab_source.readlines()\n",
    "    index2word_source = [line.rstrip() for line in f_vocab_source]\n",
    "with open(vocab_target_dir) as f_vocab_target:\n",
    "    #index2word_target = f_vocab_target.readlines()\n",
    "    index2word_target = [line.rstrip() for line in f_vocab_target]\n",
    "\n",
    "# word2index\n",
    "word2index_source = {}\n",
    "for idx, word in enumerate(index2word_source):\n",
    "    word2index_source[word] = idx\n",
    "word2index_target = {}\n",
    "for idx, word in enumerate(index2word_target):\n",
    "    word2index_target[word] = idx\n",
    "    \n",
    "# check vocabularies size    \n",
    "source_vocab_size = len(index2word_source)\n",
    "target_vocab_size = len(index2word_target)\n",
    "print(\"Total nummber of words in source vocabulary: {}\".format(len(index2word_source)))\n",
    "print(\"Total nummber of words in target vocabulary: {}\".format(len(index2word_target)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper funtions to convert sentence in natural language to list of word indexes\n",
    "def sen2idx(sentence, word2index):\n",
    "    return [word2index.get(word, 0) for word in sentence] # assume that 0 is for <unk>\n",
    "\n",
    "def sen2tensor(sentence, word2index):\n",
    "    idxes = sen2idx(sentence, word2index)\n",
    "    idxes.append(EOS_token)\n",
    "    return torch.tensor(idxes, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Encoder and Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTMCell(hidden_size, hidden_size)\n",
    "    def forward(self, input, prev_h, prev_c):\n",
    "        input_embedded = self.embedding(input)\n",
    "        h, c = self.lstm(input_embedded, (prev_h, prev_c))\n",
    "        return h, c\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, input, prev_h, prev_c):\n",
    "        input_embedded = self.embedding(input)\n",
    "        h, c = self.lstm(input_embedded, (prev_h, prev_c))\n",
    "        output =self.softmax(self.out(h))\n",
    "        return output, h, c\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "#         self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "#         self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTMCell(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, prev_h, prev_c, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], prev_h), 1)), dim=1)\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        h, c = self.lstm(output[0], (prev_h, prev_c))\n",
    "\n",
    "        output = F.log_softmax(self.out(h))\n",
    "        return output, h, c, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, max_length=MAX_LENGTH):\n",
    "    encoder_hidden_h = encoder.initHidden()\n",
    "    encoder_hidden_c = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_hidden_h, encoder_hidden_c = encoder(input_tensor[ei].view(1), encoder_hidden_h, encoder_hidden_c)\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden_c = encoder_hidden_c\n",
    "    decoder_hidden_h = encoder_hidden_h\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden_h, decoder_hidden_c = decoder(decoder_input.view(1), decoder_hidden_h, decoder_hidden_c)\n",
    "        loss += criterion(decoder_output, target_tensor[di].view(1))\n",
    "        decoder_input = target_tensor[di]\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, max_length=MAX_LENGTH):\n",
    "    encoder_hidden_h = encoder.initHidden()\n",
    "    encoder_hidden_c = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "#     print(input_length)\n",
    "    \n",
    "    for ei in range(min(input_length, max_length)):\n",
    "        encoder_hidden_h, encoder_hidden_c = encoder(input_tensor[ei].view(1), encoder_hidden_h, encoder_hidden_c)\n",
    "        encoder_outputs[ei] = encoder_hidden_h[0]\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden_c = encoder_hidden_c\n",
    "    decoder_hidden_h = encoder_hidden_h\n",
    "    \n",
    "    for di in range(target_length):\n",
    "#         decoder_output, decoder_hidden_h, decoder_hidden_c = decoder(decoder_input.view(1), decoder_hidden_h, decoder_hidden_c)\n",
    "#         loss += criterion(decoder_output, target_tensor[di].view(1))\n",
    "#         decoder_input = target_tensor[di]\n",
    "        decoder_output, decoder_hidden_h, decoder_hidden_c, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden_h, decoder_hidden_c, encoder_outputs)\n",
    "#         print(decoder_output.shape)\n",
    "#         print(target_tensor[di].view(1).shape)\n",
    "        loss += criterion(decoder_output, target_tensor[di].view(1))\n",
    "        decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), learning_rate)\n",
    "    \n",
    "    for iter in range(1, n_iters+1):\n",
    "        input_tensor = sen2tensor(sentences_source[iter-1], word2index_source)\n",
    "        target_tensor = sen2tensor(sentences_target[iter-1], word2index_target)\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter%print_every ==0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('(%d %d%%) %.4f' % (iter, iter / n_iters * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 0%) 9.7689\n",
      "(2 0%) 9.7480\n",
      "(3 0%) 9.7672\n",
      "(4 0%) 9.7140\n",
      "(5 0%) 9.7676\n",
      "(6 0%) 9.7430\n",
      "(7 0%) 9.7461\n",
      "(8 0%) 9.7596\n",
      "(9 0%) 9.7405\n",
      "(10 0%) 9.7522\n",
      "(11 0%) 9.7221\n",
      "(12 0%) 9.7295\n",
      "(13 0%) 9.6937\n",
      "(14 0%) 9.7025\n",
      "(15 0%) 9.6719\n",
      "(16 0%) 9.7168\n",
      "(17 0%) 9.7136\n",
      "(18 0%) 9.6315\n",
      "(19 0%) 9.6501\n",
      "(20 0%) 9.6224\n",
      "(21 0%) 9.6988\n",
      "(22 0%) 9.5729\n",
      "(23 0%) 9.6763\n",
      "(24 0%) 9.6138\n",
      "(25 0%) 9.6221\n",
      "(26 0%) 9.6716\n",
      "(27 0%) 9.5627\n",
      "(28 0%) 9.6106\n",
      "(29 0%) 9.6049\n",
      "(30 0%) 9.6160\n",
      "(31 0%) 9.5528\n",
      "(32 0%) 9.4708\n",
      "(33 0%) 9.4915\n",
      "(34 0%) 9.6058\n",
      "(35 0%) 9.4918\n",
      "(36 0%) 9.6004\n",
      "(37 0%) 9.6531\n",
      "(38 0%) 9.4746\n",
      "(39 0%) 9.4198\n",
      "(40 0%) 9.3809\n",
      "(41 0%) 9.5493\n",
      "(42 0%) 9.5169\n",
      "(43 0%) 9.5385\n",
      "(44 0%) 9.4711\n",
      "(45 0%) 9.3027\n",
      "(46 0%) 9.6065\n",
      "(47 0%) 9.5685\n",
      "(48 0%) 9.4791\n",
      "(49 0%) 9.2409\n",
      "(50 0%) 9.2098\n",
      "(51 0%) 9.5125\n",
      "(52 0%) 9.4247\n",
      "(53 0%) 9.2147\n",
      "(54 0%) 9.5244\n",
      "(55 0%) 9.5537\n",
      "(56 0%) 9.5278\n",
      "(57 0%) 9.3684\n",
      "(58 0%) 9.2818\n",
      "(59 0%) 9.4141\n",
      "(60 0%) 9.3359\n",
      "(61 0%) 9.2290\n",
      "(62 0%) 9.2474\n",
      "(63 0%) 9.3009\n",
      "(64 0%) 9.2622\n",
      "(65 0%) 9.0566\n",
      "(66 0%) 9.2232\n",
      "(67 0%) 9.1051\n",
      "(68 0%) 9.2622\n",
      "(69 0%) 9.0337\n",
      "(70 0%) 9.2082\n",
      "(71 0%) 9.4462\n",
      "(72 0%) 9.2841\n",
      "(73 0%) 9.4754\n",
      "(74 0%) 9.3207\n",
      "(75 0%) 9.4469\n",
      "(76 0%) 9.1818\n",
      "(77 0%) 9.2665\n",
      "(78 0%) 9.0096\n",
      "(79 0%) 9.0178\n",
      "(80 0%) 9.2336\n",
      "(81 0%) 9.1187\n",
      "(82 0%) 9.5379\n",
      "(83 0%) 9.2758\n",
      "(84 0%) 8.9776\n",
      "(85 0%) 9.0886\n",
      "(86 0%) 8.9402\n",
      "(87 0%) 9.0580\n",
      "(88 0%) 9.1160\n",
      "(89 0%) 8.7877\n",
      "(90 0%) 9.1933\n",
      "(91 0%) 8.7828\n",
      "(92 0%) 9.1147\n",
      "(93 0%) 8.8605\n",
      "(94 0%) 8.6228\n",
      "(95 0%) 8.9724\n",
      "(96 0%) 8.6954\n",
      "(97 0%) 8.9119\n",
      "(98 0%) 8.3739\n",
      "(99 0%) 8.4732\n",
      "(100 0%) 9.0962\n",
      "(101 0%) 8.8269\n",
      "(102 0%) 8.6788\n",
      "(103 0%) 8.8747\n",
      "(104 0%) 7.6401\n",
      "(105 0%) 8.9370\n",
      "(106 0%) 6.7947\n",
      "(107 0%) 8.5097\n",
      "(108 0%) 8.4046\n",
      "(109 0%) 8.1336\n",
      "(110 0%) 8.3004\n",
      "(111 0%) 8.0212\n",
      "(112 0%) 8.3847\n",
      "(113 0%) 7.9765\n",
      "(114 0%) 8.3782\n",
      "(115 0%) 7.1486\n",
      "(116 0%) 7.3458\n",
      "(117 0%) 8.9115\n",
      "(118 0%) 8.5466\n",
      "(119 0%) 8.2645\n",
      "(120 0%) 7.7625\n",
      "(121 0%) 7.7516\n",
      "(122 0%) 8.4979\n",
      "(123 0%) 6.0769\n",
      "(124 0%) 7.8394\n",
      "(125 0%) 6.1037\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-646c317bc355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m133317\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e1530444adba>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d1767176a1ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, max_length)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderLSTM(source_vocab_size, hidden_size).to(device)\n",
    "decoder1 = DecoderLSTM(hidden_size, target_vocab_size).to(device)\n",
    "trainIters(encoder1, decoder1, 133317, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaoyu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 0%) 9.7440\n",
      "(2 0%) 9.7407\n",
      "(3 0%) 9.7158\n",
      "(4 0%) 9.6977\n",
      "(5 0%) 9.7569\n",
      "(6 0%) 9.6949\n",
      "(7 0%) 9.7189\n",
      "(8 0%) 9.7101\n",
      "(9 0%) 9.7171\n",
      "(10 0%) 9.7166\n",
      "(11 0%) 9.7111\n",
      "(12 0%) 9.6984\n",
      "(13 0%) 9.6643\n",
      "(14 0%) 9.6864\n",
      "(15 0%) 9.6610\n",
      "(16 0%) 9.6248\n",
      "(17 0%) 9.6389\n",
      "(18 0%) 9.5807\n",
      "(19 0%) 9.6297\n",
      "(20 0%) 9.5947\n",
      "(21 0%) 9.5822\n",
      "(22 0%) 9.4879\n",
      "(23 0%) 9.6561\n",
      "(24 0%) 9.5249\n",
      "(25 0%) 9.5871\n",
      "(26 0%) 9.5548\n",
      "(27 0%) 9.5324\n",
      "(28 0%) 9.5565\n",
      "(29 0%) 9.5513\n",
      "(30 0%) 9.6077\n",
      "(31 0%) 9.4717\n",
      "(32 0%) 9.3608\n",
      "(33 0%) 9.4252\n",
      "(34 0%) 9.5487\n",
      "(35 0%) 9.3952\n",
      "(36 0%) 9.5239\n",
      "(37 0%) 9.4832\n",
      "(38 0%) 9.3302\n",
      "(39 0%) 9.2509\n",
      "(40 0%) 9.3108\n",
      "(41 0%) 9.3851\n",
      "(42 0%) 9.3637\n",
      "(43 0%) 9.3892\n",
      "(44 0%) 9.2423\n",
      "(45 0%) 8.9826\n",
      "(46 0%) 9.4136\n",
      "(47 0%) 9.4137\n",
      "(48 0%) 9.1472\n",
      "(49 0%) 8.8242\n",
      "(50 0%) 8.6504\n",
      "(51 0%) 9.1220\n",
      "(52 0%) 9.0072\n",
      "(53 0%) 8.8228\n",
      "(54 0%) 9.0984\n",
      "(55 0%) 9.1414\n",
      "(56 0%) 8.9019\n",
      "(57 0%) 8.8805\n",
      "(58 0%) 8.4655\n",
      "(59 0%) 8.7115\n",
      "(60 0%) 8.4812\n",
      "(61 0%) 8.1885\n",
      "(62 0%) 8.0434\n",
      "(63 0%) 8.5263\n",
      "(64 0%) 8.0180\n",
      "(65 0%) 7.8279\n",
      "(66 0%) 8.1766\n",
      "(67 0%) 7.6406\n",
      "(68 0%) 8.1841\n",
      "(69 0%) 7.4779\n",
      "(70 0%) 7.8673\n",
      "(71 0%) 8.2624\n",
      "(72 0%) 7.9188\n",
      "(73 0%) 8.3886\n",
      "(74 0%) 8.2531\n",
      "(75 0%) 8.0864\n",
      "(76 0%) 7.9503\n",
      "(77 0%) 7.9717\n",
      "(78 0%) 7.4133\n",
      "(79 0%) 7.5038\n",
      "(80 0%) 8.2625\n",
      "(81 0%) 7.8277\n",
      "(82 0%) 8.8188\n",
      "(83 0%) 7.3747\n",
      "(84 0%) 7.7432\n",
      "(85 0%) 7.4748\n",
      "(86 0%) 7.0982\n",
      "(87 0%) 7.5291\n",
      "(88 0%) 7.5467\n",
      "(89 0%) 7.2979\n",
      "(90 0%) 7.1612\n",
      "(91 0%) 6.8697\n",
      "(92 0%) 7.4257\n",
      "(93 0%) 7.5176\n",
      "(94 0%) 7.0539\n",
      "(95 0%) 6.9299\n",
      "(96 0%) 7.0801\n",
      "(97 0%) 7.5262\n",
      "(98 0%) 6.8618\n",
      "(99 0%) 6.5494\n",
      "(100 0%) 7.8435\n",
      "(101 0%) 7.7164\n",
      "(102 0%) 7.0837\n",
      "(103 0%) 7.6535\n",
      "(104 0%) 5.8707\n",
      "(105 0%) 7.8193\n",
      "(106 0%) 5.8791\n",
      "(107 0%) 7.0261\n",
      "(108 0%) 7.4491\n",
      "(109 0%) 7.4584\n",
      "(110 0%) 7.4815\n",
      "(111 0%) 6.9968\n",
      "(112 0%) 7.6656\n",
      "(113 0%) 7.0579\n",
      "(114 0%) 7.6064\n",
      "(115 0%) 6.5071\n",
      "(116 0%) 6.4369\n",
      "(117 0%) 8.3396\n",
      "(118 0%) 8.6126\n",
      "(119 0%) 7.6579\n",
      "(120 0%) 7.0342\n",
      "(121 0%) 7.0757\n",
      "(122 0%) 7.9540\n",
      "(123 0%) 5.6071\n",
      "(124 0%) 7.2414\n",
      "(125 0%) 6.2543\n",
      "(126 0%) 6.8846\n",
      "(127 0%) 8.0699\n",
      "(128 0%) 6.8188\n",
      "(129 0%) 6.5982\n",
      "(130 0%) 6.9843\n",
      "(131 0%) 6.9876\n",
      "(132 0%) 6.5505\n",
      "(133 0%) 7.4335\n",
      "(134 0%) 6.0447\n",
      "(135 0%) 7.5970\n",
      "(136 0%) 6.8465\n",
      "(137 0%) 7.1431\n",
      "(138 0%) 6.5632\n",
      "(139 0%) 5.9885\n",
      "(140 0%) 6.6169\n",
      "(141 0%) 7.0550\n",
      "(142 0%) 6.1558\n",
      "(143 0%) 7.4230\n",
      "(144 0%) 6.9059\n",
      "(145 0%) 6.9655\n",
      "(146 0%) 7.4386\n",
      "(147 0%) 6.2366\n",
      "(148 0%) 7.6554\n",
      "(149 0%) 4.6989\n",
      "(150 0%) 6.3402\n",
      "(151 0%) 7.6883\n",
      "(152 0%) 6.9799\n",
      "(153 0%) 7.2495\n",
      "(154 0%) 7.7571\n",
      "(155 0%) 6.9813\n",
      "(156 0%) 6.9394\n",
      "(157 0%) 8.0530\n",
      "(158 0%) 6.8048\n",
      "(159 0%) 6.6161\n",
      "(160 0%) 6.7480\n",
      "(161 0%) 7.4845\n",
      "(162 0%) 7.4123\n",
      "(163 0%) 7.4193\n",
      "(164 0%) 7.4412\n",
      "(165 0%) 7.5844\n",
      "(166 0%) 7.7292\n",
      "(167 0%) 7.0865\n",
      "(168 0%) 6.5370\n",
      "(169 0%) 6.8878\n",
      "(170 0%) 7.1965\n",
      "(171 0%) 7.9096\n",
      "(172 0%) 6.8123\n",
      "(173 0%) 7.2643\n",
      "(174 0%) 6.6955\n",
      "(175 0%) 7.1580\n",
      "(176 0%) 6.9370\n",
      "(177 0%) 6.5905\n",
      "(178 0%) 5.1620\n",
      "(179 0%) 6.9161\n",
      "(180 0%) 5.4099\n",
      "(181 0%) 7.4437\n",
      "(182 0%) 7.0527\n",
      "(183 0%) 6.9847\n",
      "(184 0%) 6.4918\n",
      "(185 0%) 7.6649\n",
      "(186 0%) 7.3002\n",
      "(187 0%) 5.9397\n",
      "(188 0%) 6.2142\n",
      "(189 0%) 6.7264\n",
      "(190 0%) 7.4254\n",
      "(191 0%) 6.3391\n",
      "(192 0%) 6.8937\n",
      "(193 0%) 6.7031\n",
      "(194 0%) 6.7139\n",
      "(195 0%) 7.6337\n",
      "(196 0%) 5.7390\n",
      "(197 0%) 6.9909\n",
      "(198 0%) 7.6074\n",
      "(199 0%) 7.3089\n",
      "(200 0%) 6.8751\n",
      "(201 0%) 5.1175\n",
      "(202 0%) 6.0490\n",
      "(203 0%) 8.1197\n",
      "(204 0%) 6.2195\n",
      "(205 0%) 7.3343\n",
      "(206 0%) 7.3817\n",
      "(207 0%) 5.7043\n",
      "(208 0%) 7.1077\n",
      "(209 0%) 6.2825\n",
      "(210 0%) 7.0577\n",
      "(211 0%) 6.1377\n",
      "(212 0%) 6.9491\n",
      "(213 0%) 6.9655\n",
      "(214 0%) 7.0642\n",
      "(215 0%) 7.1369\n",
      "(216 0%) 7.2388\n",
      "(217 0%) 7.4922\n",
      "(218 0%) 5.5510\n",
      "(219 0%) 7.2641\n",
      "(220 0%) 6.4096\n",
      "(221 0%) 7.8594\n",
      "(222 0%) 6.9980\n",
      "(223 0%) 6.9186\n",
      "(224 0%) 6.4755\n",
      "(225 0%) 7.1435\n",
      "(226 0%) 7.5635\n",
      "(227 0%) 6.2354\n",
      "(228 0%) 5.4727\n",
      "(229 0%) 6.9489\n",
      "(230 0%) 6.9086\n",
      "(231 0%) 6.7737\n",
      "(232 0%) 6.0706\n",
      "(233 0%) 6.8490\n",
      "(234 0%) 7.2705\n",
      "(235 0%) 6.4069\n",
      "(236 0%) 5.3915\n",
      "(237 0%) 6.0389\n",
      "(238 0%) 6.8514\n",
      "(239 0%) 6.0779\n",
      "(240 0%) 5.5934\n",
      "(241 0%) 5.9809\n",
      "(242 0%) 6.4870\n",
      "(243 0%) 7.2859\n",
      "(244 0%) 6.3442\n",
      "(245 0%) 7.0328\n",
      "(246 0%) 6.9236\n",
      "(247 0%) 7.2506\n",
      "(248 0%) 6.5390\n",
      "(249 0%) 6.8183\n",
      "(250 0%) 6.1765\n",
      "(251 0%) 6.3685\n",
      "(252 0%) 7.0244\n",
      "(253 0%) 6.4188\n",
      "(254 0%) 6.7027\n",
      "(255 0%) 7.3566\n",
      "(256 0%) 6.4558\n",
      "(257 0%) 7.3241\n",
      "(258 0%) 7.1602\n",
      "(259 0%) 6.3982\n",
      "(260 0%) 5.9755\n",
      "(261 0%) 6.4245\n",
      "(262 0%) 6.3712\n",
      "(263 0%) 6.4760\n",
      "(264 0%) 5.8313\n",
      "(265 0%) 7.3208\n",
      "(266 0%) 7.0396\n",
      "(267 0%) 6.8160\n",
      "(268 0%) 4.2551\n",
      "(269 0%) 6.1208\n",
      "(270 0%) 6.5888\n",
      "(271 0%) 6.3282\n",
      "(272 0%) 6.1635\n",
      "(273 0%) 6.7567\n",
      "(274 0%) 6.4493\n",
      "(275 0%) 5.5892\n",
      "(276 0%) 4.7215\n",
      "(277 0%) 7.3135\n",
      "(278 0%) 5.0928\n",
      "(279 0%) 6.8412\n",
      "(280 0%) 6.4651\n",
      "(281 0%) 6.3401\n",
      "(282 0%) 6.3348\n",
      "(283 0%) 6.4435\n",
      "(284 0%) 6.2676\n",
      "(285 0%) 5.5709\n",
      "(286 0%) 6.6526\n",
      "(287 0%) 6.5038\n",
      "(288 0%) 6.8104\n",
      "(289 0%) 6.4482\n",
      "(290 0%) 5.9752\n",
      "(291 0%) 6.7104\n",
      "(292 0%) 5.9461\n",
      "(293 0%) 5.7320\n",
      "(294 0%) 6.2518\n",
      "(295 0%) 7.2651\n",
      "(296 0%) 6.6441\n",
      "(297 0%) 6.4817\n",
      "(298 0%) 6.1644\n",
      "(299 0%) 6.1783\n",
      "(300 0%) 6.2150\n",
      "(301 0%) 6.0723\n",
      "(302 0%) 5.8903\n",
      "(303 0%) 5.7698\n",
      "(304 0%) 4.9151\n",
      "(305 0%) 5.6690\n",
      "(306 0%) 6.8578\n",
      "(307 0%) 6.5483\n",
      "(308 0%) 4.7299\n",
      "(309 0%) 6.0784\n",
      "(310 0%) 6.7107\n",
      "(311 0%) 5.3257\n",
      "(312 0%) 5.2822\n",
      "(313 0%) 5.7686\n",
      "(314 0%) 6.3369\n",
      "(315 0%) 6.5512\n",
      "(316 0%) 5.2355\n",
      "(317 0%) 5.7837\n",
      "(318 0%) 6.5833\n",
      "(319 0%) 4.7141\n",
      "(320 0%) 6.1363\n",
      "(321 0%) 4.8749\n",
      "(322 0%) 5.8265\n",
      "(323 0%) 5.6180\n",
      "(324 0%) 5.9020\n",
      "(325 0%) 5.6885\n",
      "(326 0%) 6.3940\n",
      "(327 0%) 5.8952\n",
      "(328 0%) 6.3595\n",
      "(329 0%) 5.7192\n",
      "(330 0%) 6.1737\n",
      "(331 0%) 6.0319\n",
      "(332 0%) 5.5168\n",
      "(333 0%) 5.7765\n",
      "(334 0%) 5.6684\n",
      "(335 0%) 6.4958\n",
      "(336 0%) 6.4903\n",
      "(337 0%) 4.6532\n",
      "(338 0%) 6.2483\n",
      "(339 0%) 6.2640\n",
      "(340 0%) 6.2472\n",
      "(341 0%) 6.4495\n",
      "(342 0%) 5.3381\n",
      "(343 0%) 4.7261\n",
      "(344 0%) 5.5162\n",
      "(345 0%) 5.6171\n",
      "(346 0%) 6.1792\n",
      "(347 0%) 5.9547\n",
      "(348 0%) 5.5192\n",
      "(349 0%) 5.8933\n",
      "(350 0%) 5.8466\n",
      "(351 0%) 4.3840\n",
      "(352 0%) 5.3328\n",
      "(353 0%) 4.6905\n",
      "(354 0%) 4.8178\n",
      "(355 0%) 4.5349\n",
      "(356 0%) 4.0118\n",
      "(357 0%) 5.4270\n",
      "(358 0%) 6.0611\n",
      "(359 0%) 5.6788\n",
      "(360 0%) 4.5525\n",
      "(361 0%) 6.6289\n",
      "(362 0%) 7.2432\n",
      "(363 0%) 2.6449\n",
      "(364 0%) 5.9529\n",
      "(365 0%) 7.0618\n",
      "(366 0%) 6.4723\n",
      "(367 0%) 5.9194\n",
      "(368 0%) 5.5435\n",
      "(369 0%) 5.7635\n",
      "(370 0%) 6.1283\n",
      "(371 0%) 5.8498\n",
      "(372 0%) 7.0214\n",
      "(373 0%) 6.0881\n",
      "(374 0%) 6.5769\n",
      "(375 0%) 6.1467\n",
      "(376 0%) 4.6809\n",
      "(377 0%) 6.0130\n",
      "(378 0%) 5.7181\n",
      "(379 0%) 6.2014\n",
      "(380 0%) 7.0419\n",
      "(381 0%) 5.8976\n",
      "(382 0%) 5.7755\n",
      "(383 0%) 5.9030\n",
      "(384 0%) 5.5528\n",
      "(385 0%) 4.8954\n",
      "(386 0%) 5.1436\n",
      "(387 0%) 5.5928\n",
      "(388 0%) 5.9636\n",
      "(389 0%) 5.4625\n",
      "(390 0%) 5.9812\n",
      "(391 0%) 5.9434\n",
      "(392 0%) 5.3151\n",
      "(393 0%) 5.0922\n",
      "(394 0%) 5.9961\n",
      "(395 0%) 6.3816\n",
      "(396 0%) 6.0779\n",
      "(397 0%) 6.6851\n",
      "(398 0%) 6.2641\n",
      "(399 0%) 6.0265\n",
      "(400 0%) 5.0858\n",
      "(401 0%) 4.5960\n",
      "(402 0%) 5.4991\n",
      "(403 0%) 5.6999\n",
      "(404 0%) 5.7288\n",
      "(405 0%) 5.6315\n",
      "(406 0%) 5.6038\n",
      "(407 0%) 5.2511\n",
      "(408 0%) 4.3224\n",
      "(409 0%) 6.0138\n",
      "(410 0%) 5.6132\n",
      "(411 0%) 7.1555\n",
      "(412 0%) 6.7625\n",
      "(413 0%) 6.0976\n",
      "(414 0%) 4.6205\n",
      "(415 0%) 4.7592\n",
      "(416 0%) 6.9361\n",
      "(417 0%) 5.3413\n",
      "(418 0%) 5.1980\n",
      "(419 0%) 5.4439\n",
      "(420 0%) 3.0899\n",
      "(421 0%) 9.9759\n",
      "(422 0%) 8.0824\n",
      "(423 0%) 5.8985\n",
      "(424 0%) 6.1945\n",
      "(425 0%) 6.8699\n",
      "(426 0%) 6.1222\n",
      "(427 0%) 4.7427\n",
      "(428 0%) 6.8328\n",
      "(429 0%) 2.3130\n",
      "(430 0%) 4.0072\n",
      "(431 0%) 5.8331\n",
      "(432 0%) 4.4335\n",
      "(433 0%) 6.2729\n",
      "(434 0%) 6.2606\n",
      "(435 0%) 6.0111\n",
      "(436 0%) 5.9756\n",
      "(437 0%) 6.1284\n",
      "(438 0%) 5.8549\n",
      "(439 0%) 5.4136\n",
      "(440 0%) 5.9470\n",
      "(441 0%) 5.7094\n",
      "(442 0%) 5.1047\n",
      "(443 0%) 6.3186\n",
      "(444 0%) 5.1006\n",
      "(445 0%) 6.4246\n",
      "(446 0%) 4.5737\n",
      "(447 0%) 5.4155\n",
      "(448 0%) 6.0972\n",
      "(449 0%) 5.6856\n",
      "(450 0%) 6.0194\n",
      "(451 0%) 5.9836\n",
      "(452 0%) 6.4761\n",
      "(453 0%) 4.6053\n",
      "(454 0%) 6.1694\n",
      "(455 0%) 5.8325\n",
      "(456 0%) 6.3222\n",
      "(457 0%) 5.7228\n",
      "(458 0%) 5.3038\n",
      "(459 0%) 3.2289\n",
      "(460 0%) 4.7747\n",
      "(461 0%) 2.6326\n",
      "(462 0%) 6.3058\n",
      "(463 0%) 4.7112\n",
      "(464 0%) 6.1626\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a97d97612421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecoder2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m133317\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e1530444adba>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fb9e8511e8f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, max_length)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder2 = EncoderLSTM(source_vocab_size, hidden_size).to(device)\n",
    "decoder2 = AttnDecoderLSTM(hidden_size, target_vocab_size).to(device)\n",
    "trainIters(encoder2, decoder2, 133317, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
